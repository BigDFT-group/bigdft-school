{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDuqtyWFwZk3"
   },
   "source": [
    "# Install BigDFT code or client in Google Colab, locally or into your google drive folder\n",
    "This notebook will install the code in your google drive folder, which will be useful to excute the other tutorials of the school.\n",
    "\n",
    "You should provide authorisation to access your google drive after the execution of the first cell.\n",
    "\n",
    "The files of the school will go in the `bigdft-school` directory. Such folder can be moved to your local disk or deleted once you are done.\n",
    "\n",
    "The entire installation procedure should take about one minute.\n",
    "\n",
    "In the forthcoming lessons, some other packages will be also installed in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'install' from '/work/gitprojects/bigdft-school/CCWinterSchool-2024/../packaging/install.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from sys import path\n",
    "path.insert(0,'../packaging')\n",
    "import install\n",
    "reload(install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: wget https://raw.githubusercontent.com/BigDFT-group/bigdft-school/data/data/session1.tar.xz -O session1.tar.xz 2>/dev/null\n",
      "Error Occurred:  \n",
      " --2024-01-27 14:59:00--  https://raw.githubusercontent.com/BigDFT-group/bigdft-school/data/data/session1.tar.xz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 132 [text/plain]\n",
      "Saving to: ‘session1.tar.xz’\n",
      "\n",
      "     0K                                                       100% 5.80M=0s\n",
      "\n",
      "2024-01-27 14:59:00 (5.80 MB/s) - ‘session1.tar.xz’ saved [132/132]\n",
      "\n",
      "--2024-01-27 14:59:00--  http://2%3E/dev/null\n",
      "Resolving 2> (2>)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘2>’\n",
      "FINISHED --2024-01-27 14:59:00--\n",
      "Total wall clock time: 0.2s\n",
      "Downloaded: 1 files, 132 in 0s (5.80 MB/s)\n",
      "\n",
      "Executing: mkdir -p /work/gitprojects/bigdft-school/CCWinterSchool-2024\n",
      "\n",
      "Executing: tar xJf session1.tar.xz -C .\n",
      "Error Occurred:  \n",
      " xz: (stdin): File format not recognized\n",
      "tar: Child returned status 1\n",
      "tar: Error is not recoverable: exiting now\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.data('data/session1.tar.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../packaging',\n",
       " '/work/gitprojects/bigdft-school/CCWinterSchool-2024',\n",
       " '/opt/bigdft/sources/jhbuild/sitecustomize',\n",
       " '',\n",
       " '/lib/python3.9/site-packages',\n",
       " '/opt/intel/oneapi/advisor/2023.1.0/pythonapi',\n",
       " '/opt/bigdft/install/lib/python3.9/site-packages',\n",
       " '/opt/upstream/lib/python3.9/site-packages',\n",
       " '/opt/intel/oneapi/intelpython/latest/lib/python39.zip',\n",
       " '/opt/intel/oneapi/intelpython/latest/lib/python3.9',\n",
       " '/opt/intel/oneapi/intelpython/latest/lib/python3.9/lib-dynload',\n",
       " '/home/genovese/.local/lib/python3.9/site-packages',\n",
       " '/opt/intel/oneapi/intelpython/latest/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import path\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sha_and_size(filename):\n",
    "    with open(filename) as ifile:\n",
    "        for line in ifile.readlines():\n",
    "            if 'sha256' in line:\n",
    "                sha=line.split(':')[-1].rstrip('\\n')\n",
    "            if 'size' in line:\n",
    "                size=line.split()[-1].rstrip('\\n')\n",
    "    return sha,size\n",
    "def get_curl_command(sha,size,repo):\n",
    "    basecurl=['curl', '-X', 'POST', '-H','\"Accept: application/vnd.git-lfs+json\"',\n",
    "              '-H','\"Content-type: application/json\"',\n",
    "              '-d']\n",
    "    datas='{\"operation\": \"download\", \"transfer\": [\"basic\"], \"objects\": [{\"oid\": \"'+sha+'\", \"size\": '+size+'}]}'\n",
    "    repos=repo+\".git/info/lfs/objects/batch\"\n",
    "    return basecurl+[\"'\"+datas+\"'\",repos,'-o','href.json','--http1.1']\n",
    "def data_archive(archive):\n",
    "    from os import system, path\n",
    "    from json import load\n",
    "    lfs='lfs.info'\n",
    "    install.execute('wget', path.join(install.data_url,archive), '-O', lfs)\n",
    "    system(\" \".join(get_curl_command(*get_sha_and_size(lfs),install.school_url)))\n",
    "    with open('href.json') as jfile:\n",
    "        href_d=load(jfile)\n",
    "    url=href_d['objects'][0]['actions']['download']['href']\n",
    "    install.execute('wget', url, '-O', path.basename(archive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: wget https://raw.githubusercontent.com/BigDFT-group/bigdft-school/data/data/session1.tar.xz -O lfs.info\n",
      "--2024-01-27 17:28:06--  https://raw.githubusercontent.com/BigDFT-group/bigdft-school/data/data/session1.tar.xz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 132 [text/plain]\n",
      "Saving to: ‘lfs.info’\n",
      "\n",
      "     0K                                                       100% 11.8M=0s\n",
      "\n",
      "2024-01-27 17:28:06 (11.8 MB/s) - ‘lfs.info’ saved [132/132]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   902  100   747  100   155   1908    395 --:--:-- --:--:-- --:--:--  2301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: wget https://github-cloud.githubusercontent.com/alambic/media/498411787/04/51/0451bb81fd450e1700088fa4b591118ddfcd9eee51328df835bfe4e54f06ce44?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5BA2674WPWWEFGQ5%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T172806Z&X-Amz-Expires=3600&X-Amz-Signature=f9518cdbcf9d46aa4295b12705850b97d54cfc8248d0bb1d46c9d2c76216e0f3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=539378885&token=1 -O session1.tar.xz\n",
      "--2024-01-27 17:28:06--  https://github-cloud.githubusercontent.com/alambic/media/498411787/04/51/0451bb81fd450e1700088fa4b591118ddfcd9eee51328df835bfe4e54f06ce44?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5BA2674WPWWEFGQ5%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T172806Z&X-Amz-Expires=3600&X-Amz-Signature=f9518cdbcf9d46aa4295b12705850b97d54cfc8248d0bb1d46c9d2c76216e0f3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=539378885&token=1\n",
      "Resolving github-cloud.githubusercontent.com (github-cloud.githubusercontent.com)... 185.199.111.154, 185.199.110.154, 185.199.109.154, ...\n",
      "Connecting to github-cloud.githubusercontent.com (github-cloud.githubusercontent.com)|185.199.111.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3298788 (3.1M) [application/octet-stream]\n",
      "Saving to: ‘session1.tar.xz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1% 3.57M 1s\n",
      "    50K .......... .......... .......... .......... ..........  3% 4.78M 1s\n",
      "   100K .......... .......... .......... .......... ..........  4% 17.4M 1s\n",
      "   150K .......... .......... .......... .......... ..........  6% 21.6M 0s\n",
      "   200K .......... .......... .......... .......... ..........  7% 7.57M 0s\n",
      "   250K .......... .......... .......... .......... ..........  9% 40.2M 0s\n",
      "   300K .......... .......... .......... .......... .......... 10% 24.5M 0s\n",
      "   350K .......... .......... .......... .......... .......... 12% 44.9M 0s\n",
      "   400K .......... .......... .......... .......... .......... 13% 88.6M 0s\n",
      "   450K .......... .......... .......... .......... .......... 15% 38.0M 0s\n",
      "   500K .......... .......... .......... .......... .......... 17% 8.87M 0s\n",
      "   550K .......... .......... .......... .......... .......... 18%  201M 0s\n",
      "   600K .......... .......... .......... .......... .......... 20%  114M 0s\n",
      "   650K .......... .......... .......... .......... .......... 21% 45.3M 0s\n",
      "   700K .......... .......... .......... .......... .......... 23% 44.7M 0s\n",
      "   750K .......... .......... .......... .......... .......... 24%  102M 0s\n",
      "   800K .......... .......... .......... .......... .......... 26%  101M 0s\n",
      "   850K .......... .......... .......... .......... .......... 27%  180M 0s\n",
      "   900K .......... .......... .......... .......... .......... 29% 37.0M 0s\n",
      "   950K .......... .......... .......... .......... .......... 31%  100M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 32% 31.1M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 34%  142M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 35% 15.4M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 37% 92.2M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 38%  111M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 40%  107M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 41%  163M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 43% 92.7M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 45% 94.0M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 46%  102M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 48%  184M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 49%  106M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 51% 95.3M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 52%  112M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 54% 97.9M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 55% 97.5M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 57%  104M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 58% 99.9M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 60%  142M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 62%  100M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 63% 94.0M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 65%  113M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 66% 94.5M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 68% 96.5M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 69% 32.9M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 71%  107M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 72% 98.8M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 74%  163M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 76%  106M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 77% 74.1M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 79%  159M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 80%  101M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 82% 98.0M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 83%  105M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 85%  154M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 86% 97.1M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 88% 99.0M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 90%  108M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 91%  115M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 93% 95.1M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 94% 91.8M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 96%  104M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 97% 95.6M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 99%  129M 0s\n",
      "  3200K .......... .......... .                               100%  340M=0.08s\n",
      "\n",
      "2024-01-27 17:28:07 (40.4 MB/s) - ‘session1.tar.xz’ saved [3298788/3298788]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_archive('data/session1.tar.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curl -X POST -H \"Accept: application/vnd.git-lfs+json\" -H \"Content-type: application/json\" -d \\'{\"operation\": \"download\", \"transfer\": [\"basic\"],\"objects\": [{\"oid\": \"0451bb81fd450e1700088fa4b591118ddfcd9eee51328df835bfe4e54f06ce44\", \"size\": 3298788}]\\'} https://github.com/BigDFT-group/bigdft-school.git/info/lfs/objects/batch'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_curl_command(*get_sha_and_size('session1.tar.xz'),\"https://github.com/BigDFT-group/bigdft-school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   902  100   747  100   155   2229    462 --:--:-- --:--:-- --:--:--  2700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import system\n",
    "system(\" \".join(get_curl_command(*get_sha_and_size('session1.tar.xz'),\"https://github.com/BigDFT-group/bigdft-school\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m ifile:\n\u001b[0;32m----> 3\u001b[0m     href\u001b[38;5;241m=\u001b[39m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mifile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "with open('href.json') as ifile:\n",
    "    href=load(ifile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85XHZLop-7GY"
   },
   "outputs": [],
   "source": [
    "!wget https://gitlab.com/luigigenovese/bigdft-school/-/raw/main/packaging/install.py &> /dev/null\n",
    "import install\n",
    "install.full_suite() # Kernel will restart after this, it is normal. Count about 3 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae9PJolRCX1P"
   },
   "source": [
    "The notebook should have restarted at present. You may want to remove the runtime warning at the bottom of the page.\n",
    "\n",
    "Also, you may have seen a message about an inconsistent environment at the end of the installation procedure. This message is harmless, you can safely ignore it.\n",
    "\n",
    "The install module will have to be imported again to set the notebook ready for execution.\n",
    "\n",
    "To see if everything looks OK you can execute this cell to see if an energy value is output at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm0l6B97wZk8"
   },
   "outputs": [],
   "source": [
    "import install\n",
    "install.set_ready() #this resets the basic environment variables and puts us in the correct directory, (only needed for the full suite installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kR0i8GZ6_1Jh"
   },
   "outputs": [],
   "source": [
    "# Test that we can import everything\n",
    "import futile\n",
    "import BigDFT\n",
    "\n",
    "# Test A Full Calculation with PyBigDFT\n",
    "from BigDFT.Systems import System\n",
    "from BigDFT.Fragments import Fragment\n",
    "from BigDFT.Atoms import Atom\n",
    "\n",
    "at = Atom({\"He\": [0, 0, 0]})\n",
    "frag = Fragment([at])\n",
    "sys = System({\"FRA:0\": frag})\n",
    "\n",
    "from BigDFT.Calculators import SystemCalculator\n",
    "code = SystemCalculator(skip=True) #this skip option would not run the code if the result is present.\n",
    "\n",
    "from BigDFT.Inputfiles import Inputfile\n",
    "inp = Inputfile()\n",
    "inp.set_xc(\"PBE\")\n",
    "inp.set_hgrid(0.4)\n",
    "\n",
    "log = code.run(sys=sys, input=inp)\n",
    "print(log.energy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGzsd8RG2fzC"
   },
   "source": [
    "Such energy value should be `-2.8893983558799454` (Hartree)\n",
    "\n",
    "We can now present another possible installation of the code, which is performed via only the bigdft client. This installation is lighter as it only involves the python pakages employed by PyBigDFT for pre- and post- processing, and it will be enough for most of the tutorials of the school.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKL2-3DY3Duf"
   },
   "outputs": [],
   "source": [
    "import install\n",
    "install.client(locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPRVpI7F6RFp"
   },
   "source": [
    "# Verification step\n",
    "Rerun the execution step now that the client is installed instead to see if the energy is the same even without the BigDFT executable.\n",
    "\n",
    "Tips: restart the runtime without erasing the files, and run the installation command. (`import install` first, then `install.client(locally=True)`)\n",
    "\n",
    "# Installation of the client on your google drive\n",
    "\n",
    "Install the bigdft client on your google drive folder to continue with the school trainings.\n",
    "\n",
    "To trigger this installation you have to authorize the usage of your google drive folder. This would prevent the installation to be performed every time.\n",
    "\n",
    "Tips: it is just enough to remove the ``locally=True`` option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7UL4ZIBId2U"
   },
   "outputs": [],
   "source": [
    "install.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCKvJttDV4qy"
   },
   "source": [
    "# Installation form\n",
    "In the forthcoming notebooks you have to setup the bigdft installation each time.\n",
    "If you performed your installation on google drive, this will just remount your drive and set the correct python environment. For the other installation flavours, it would be necessary to perform the installation steps from scratch.\n",
    "We include a form at the beginning of each notebook to suggest the preferred installation method for each session. When suitable, you can choose another one.\n",
    "\n",
    "If you want to test the form, restart the runtime, choose your installation method, and push the \"Play\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1T80WRo-_Sim"
   },
   "outputs": [],
   "source": [
    "install = \"client (Google drive)\" #@param [\"full_suite\", \"client (Google drive)\", \"client\"]\n",
    "install_var=install\n",
    "!wget https://gitlab.com/luigigenovese/bigdft-school/-/raw/main/packaging/install.py &> /dev/null\n",
    "args={'locally': True} if install == 'client' else {}\n",
    "import install\n",
    "getattr(install,install_var.split()[0])(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvAx2lawWjTV"
   },
   "source": [
    "# Closing the environment\n",
    "\n",
    "There are also commodity functions which unmount your google drive (to keep it in sync with the data that have been copied in it) and to erase every file that has been put in by this school project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwQcIIyMXAdV",
    "outputId": "1295c053-cc68-4206-bd28-7fff13d78c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: rm -rf /content/drive/MyDrive/bigdft-school\n"
     ]
    }
   ],
   "source": [
    "#this command can be executed to clean completely the google drive (don't do this now, but at the end of the school!)\n",
    "# install.purge_drive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_VaMsDyI3d2"
   },
   "outputs": [],
   "source": [
    "#we flush the google drive at the end of the process (this can take a long time. You can install locally the client if it takes too long)\n",
    "install.close_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjFVe4xlkMyc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
