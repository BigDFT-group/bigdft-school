{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this tutorial, we will introduce the `remotemanager` library. Previously, we have seen how PyBigDFT can be useful for setting up and running BigDFT calculations. Unfortunately, most calculations we want to run are too computationally demanding for your workstation. This isn't limited to BigDFT runs: you may want to easily access a more powerful machine for pre/post-processing. \n",
    "\n",
    "The `remotemanager` library is designed with this in mind. What `remotemanager` does it allows you to run any python function you define on a remote computer. This will allow you to easily mix the interactive experience of your Jupyter notebook with the power of a supercomputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Installation can be done via a pip install:\n",
    "\n",
    "`pip install remotemanager` for the most recent stable version.\n",
    "\n",
    "We will also get some other goodies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: remotemanager in /home/genovese/.local/lib/python3.9/site-packages (0.6.1)\n",
      "Requirement already satisfied: pyyaml in /opt/upstream/lib/python3.9/site-packages (from remotemanager) (6.0)\n",
      "Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from remotemanager) (2.28.1)\n",
      "Requirement already satisfied: numpy in /home/genovese/.local/lib/python3.9/site-packages (from remotemanager) (1.22.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->remotemanager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->remotemanager) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->remotemanager) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->remotemanager) (3.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U remotemanager\n",
    "! pip install -q requests\n",
    "! pip install -q scipy\n",
    "! pip install -q jsonpickle\n",
    "! pip install -q dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Creation\n",
    "First, we need to define the remote machine we are interested in running on. To do so, we use the URL class. In the simplest case, we can define our own workstation as the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Google Colab seems far too verbose so we turn down the logging...\n",
    "from remotemanager import Logger\n",
    "Logger.level = \"CRITICAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from remotemanager import URL\n",
    "connection = URL(host='localhost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example connection is simply pointed at `localhost`, however you may define a connection to a machine with address or IP:\n",
    "\n",
    "`connection = URL(user='username', host='remote.connection.address')`\n",
    "\n",
    "`connection = URL(user='username', host='192.168.123.456')`\n",
    "\n",
    ".. note::\n",
    "    The only requirement for `URL` to function is that you must be able to ssh into the remote machine without any additional prompts from the remote. For connection difficulties regarding permissions, see the [relevant section](../Introduction.html#Connecting-to-a-Remote-Machine) of the introduction.\n",
    "    \n",
    "We can also access some of the predefined computers which contain some predefined options and environment settings. You can further [build your own custom computer](https://l_sim.gitlab.io/remotemanager/tutorials/Submitting%20Via%20Scheduler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polling url https://gitlab.com/l_sim/remotemanager-computers/-/raw/main/storage/archer2.yaml\n",
      "Grabbed file 'archer2.yaml'\n"
     ]
    }
   ],
   "source": [
    "from remotemanager.connection.computers.base import BaseComputer\n",
    "archer_connection = BaseComputer.from_repo(name = \"archer2\")\n",
    "archer_connection.mpi = 16\n",
    "archer_connection.omp = 8\n",
    "archer_connection.time = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer classes automatically generate jobscripts which are used to run your python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 total mpi requested\n",
      "#!/bin/bash\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks=128\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --walltime=00:01:40\n",
      "#SBATCH --ntasks=16\n",
      "#SBATCH --job-name=test_job\n",
      "#SBATCH --qos=standard\n",
      "#SBATCH --export=none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(archer_connection.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For basic commands, url provides a `cmd` method, which will execute any strings given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bigdft/sdk:oneapi2023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.cmd('hostname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "The `remotemanager` library is able to execute user defined python functions at the location of choice. Below is a basic function example which will serve our purposes for this guide\n",
    "\n",
    ".. note::\n",
    "    The function must stand by itself when running, so any imports or necessary functionality should be contained within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(a, b):\n",
    "    import time\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function would run just fine on any workstation, however imagine that the function is something significantly more demanding. We would need to connect to some more powerful resources for this.\n",
    "\n",
    "For function execution, we require a `Dataset`. Think of this dataset as a container for your function, with calculations to be added later on.\n",
    "\n",
    "Like `URL`, this can be imported directly from `remotemanager`\n",
    "\n",
    "To create a dataset, the only requirement is a callable function object. You must pass this object to the Dataset\n",
    "\n",
    ".. note::\n",
    "    When passing a function to the dataset, do not call it within the assigment. For example, for our multiply function, we should pass `function=multiply` _not_ `function=multiply()`\n",
    "\n",
    "Here we are additionally specifying the `local_dir` and the `remote_dir`, which tells the Dataset where to put all relevant files on the local and remote machines, respectively.\n",
    "\n",
    "If it suits your workflow, you can additionally specify a `run_dir` when appending a run. This is an additional folder within `remote_dir` where the script will be executed from. Thus, any files created by your function will be placed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from remotemanager import Dataset\n",
    "\n",
    "ds = Dataset(function=multiply,\n",
    "             url=connection,\n",
    "             local_dir='temp_local',\n",
    "             remote_dir='temp_remote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating runs\n",
    "\n",
    "As the dataset is simply a container for the function, it is essentially useless in this state. To get some use out of it, we must append some runs.\n",
    "\n",
    "To do this we use the `Dataset.append_run()` method. This will take the arguments in `dict` format, and store them for later.\n",
    "\n",
    "You may do this in any way you see fit, the important part is to pass a dictionary which contains all ncessary arguments for the running of your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runner runner-3 already exists\n",
      "runner runner-3 already exists\n",
      "runner runner-3 already exists\n"
     ]
    }
   ],
   "source": [
    "runs = [[21, 2],\n",
    "        [64, 8],\n",
    "        [10, 7]]\n",
    "\n",
    "for run in runs:\n",
    "    \n",
    "    a = run[0]\n",
    "    b = run[1]\n",
    "    \n",
    "    arguments = {'a': a, 'b': b}\n",
    "    \n",
    "    ds.append_run(arguments=arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running and Retrieving your results\n",
    "\n",
    "Now we have created a dataset and appended some runs, we can launch the calculations. This is done via the Dataset.run() method\n",
    "\n",
    "Once the runs have completed, you can retrieve your results with `ds.fetch_results()`, and access them via `ds.results` once this is done\n",
    "\n",
    ".. note::\n",
    "    Be aware that the `fetch_results` method does not return your results, simply stores them in the `results` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessing run for runner dataset-62eb4971-runner-0... checks passed, running\n",
      "assessing run for runner dataset-62eb4971-runner-1... checks passed, running\n",
      "assessing run for runner dataset-62eb4971-runner-2... checks passed, running\n"
     ]
    }
   ],
   "source": [
    "ds.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking remotely for finished runs\n",
      "checking remotely for finished runs\n"
     ]
    }
   ],
   "source": [
    "# fetch the results, this loads them into the ds.results property for later access\n",
    "import time\n",
    "\n",
    "while not ds.is_finished:\n",
    "    time.sleep(3)\n",
    "_ = ds.fetch_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 512, 70]\n"
     ]
    }
   ],
   "source": [
    "# access this property any time after the results have been fetched. \n",
    "# This prevents the dataset attempting to poll the remote each time\n",
    "\n",
    "print(ds.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic Commands\n",
    "For some tasks, the use of a dataset can be overkill and make it hard to read your notebook. For simple remote tasks, we have created the `sanzu` magic commands, which automatically wrap Jupyter cells for remote execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext remotemanager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an arbitrary cell in a Jupyter notebook, and decorate it so that it runs on the remote machine. The `%%sanzu` magic takes the same list of arguments you would send to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended run runner-0\n",
      "assessing run for runner dataset-cfec147e-runner-0... checks passed, running\n",
      "checking remotely for finished runs\n"
     ]
    }
   ],
   "source": [
    "%%sanzu url=connection, remote_dir=\"rmagic\"\n",
    "from time import sleep\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the cell above again, you will find that the result has been cached, and the function returns instantly. Now let's try a more useful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended run runner-0\n",
      "assessing run for runner dataset-a5d0ca1e-runner-0... checks passed, running\n",
      "checking remotely for finished runs\n"
     ]
    }
   ],
   "source": [
    "%%sanzu url=connection\n",
    "%%sargs N = 1000, hermitian=True\n",
    "%%sargs idx = 0\n",
    "from numpy.random import rand\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "mat = rand(N, N)\n",
    "if hermitian:\n",
    "    mat += mat.T\n",
    "\n",
    "vals, vecs = eigh(mat)\n",
    "vals[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we're build a random matrix, and computing its lowest eigenvalue. The `%%sargs` lines were used  In Jupyter, the last line of a cell is automatically returned. We can access this result through the magic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-25.733816660126095]\n"
     ]
    }
   ],
   "source": [
    "print(magic_dataset.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization and File Passing\n",
    "The way that `remotemanager` works is that it serializes whatever objects are passed to file. This can lead to some trip ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type UUID is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/remotemanager/dataset/runner.py:83\u001b[0m, in \u001b[0;36mRunner.__init__\u001b[0;34m(self, arguments, dbfile, parent, self_id, extra_files_send, extra_files_recv, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     uuid_slug \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(arguments) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03ma serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m(to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type UUID is not JSON serializable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msanzu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%%\u001b[39;49;00m\u001b[38;5;124;43msargs x = uuid1()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(x)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/remotemanager/jupyter/magic.py:67\u001b[0m, in \u001b[0;36mRCell.sanzu\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Build the runner and run\u001b[39;00m\n\u001b[1;32m     66\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset(function\u001b[38;5;241m=\u001b[39mfstr, block_reinit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m ds\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cmd \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mrun_cmds:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/remotemanager/dataset/dataset.py:488\u001b[0m, in \u001b[0;36mDataset.append_run\u001b[0;34m(self, args, arguments, name, extra_files_send, extra_files_recv, dependency_call, verbose, quiet, **run_args)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     r_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunner-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 488\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdbfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mself_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_files_send\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files_send\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_files_recv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files_recv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m tmp\u001b[38;5;241m.\u001b[39mresult_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserialiser\u001b[38;5;241m.\u001b[39mextension\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tmp\u001b[38;5;241m.\u001b[39muuid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uuids:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/remotemanager/dataset/runner.py:92\u001b[0m, in \u001b[0;36mRunner.__init__\u001b[0;34m(self, arguments, dbfile, parent, self_id, extra_files_send, extra_files_recv, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mlocal_dir):\n\u001b[1;32m     90\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mlocal_dir)\n\u001b[0;32m---> 92\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(lpath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserialiser\u001b[38;5;241m.\u001b[39mwrite_mode) \u001b[38;5;28;01mas\u001b[39;00m o:\n\u001b[1;32m     94\u001b[0m     o\u001b[38;5;241m.\u001b[39mwrite(content)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/remotemanager/serialisation/serialjson.py:13\u001b[0m, in \u001b[0;36mserialjson.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m     12\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_to_list(obj)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type UUID is not JSON serializable"
     ]
    }
   ],
   "source": [
    "%%sanzu\n",
    "%%sargs x = uuid1()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails, because the default serializer writes json, and uuid is not a simple type. To pass this kind of type, we need to switch the serialiser to something more flexible. We recommend `jsonpickle` and `dill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remotemanager.serialisation import serialjsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended run runner-0\n",
      "assessing run for runner dataset-79333d30-runner-0... checks passed, running\n",
      "checking remotely for finished runs\n"
     ]
    }
   ],
   "source": [
    "%%sanzu serialiser = serialjsonpickle()\n",
    "%%sargs x = uuid1()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UUID('5643024e-ffbd-11ed-95a8-ccd9ac16bd18')]\n"
     ]
    }
   ],
   "source": [
    "print(magic_dataset.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to take care of the remote environment and make sure any type that you send is available there. If the remote computer's Python environment is very limited, sending files back and forth can be a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"send_me.txt\", \"w\") as ofile:\n",
    "    ofile.write(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended run runner-0\n",
      "assessing run for runner dataset-b42beebf-runner-0... checks passed, running\n",
      "checking remotely for finished runs\n"
     ]
    }
   ],
   "source": [
    "%%sanzu extra_files_send = [\"send_me.txt\"]\n",
    "%%sanzu extra_files_recv = [\"recv_me.txt\"]\n",
    "with open(\"send_me.txt\") as ifile:\n",
    "    f = next(ifile)\n",
    "with open(\"recv_me.txt\", \"w\") as ofile:\n",
    "    ofile.write(f + \" worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test worked\n"
     ]
    }
   ],
   "source": [
    "with open(\"temp_runner_local/recv_me.txt\") as ifile:\n",
    "    print(next(ifile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Install remotemanager on your own machine and access the Saga supercomputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remote Manager run in a nutshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(hgrid):\n",
    "    from BigDFT.Calculators import SystemCalculator\n",
    "    from BigDFT.Inputfiles import Inputfile\n",
    "    from BigDFT.Database.Molecules import get_molecule\n",
    "    \n",
    "    sys = get_molecule(\"N2\")\n",
    "    inp = Inputfile()\n",
    "    inp.set_hgrid(hgrid)\n",
    "    calc = SystemCalculator()\n",
    "    log = calc.run(sys=sys, input=inp, name=str(hgrid))\n",
    "    \n",
    "    return log.energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remotemanager import URL  # Replace this with the computer of your choice\n",
    "from remotemanager import Dataset  # Store a set of remote calculations\n",
    "url = URL()\n",
    "ds = Dataset(function=calculate, url=url)\n",
    "for h in [0.3, 0.35, 0.4]:\n",
    "    ds.append_run({\"hgrid\": h})\n",
    "ds.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while not all(ds.is_finished):\n",
    "    sleep(10)\n",
    "ds.fetch_results()\n",
    "print(ds.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sanzu url=url\n",
    "%%sargs hgrid = 0.35\n",
    "from BigDFT.Logfiles import Logfile\n",
    "log = Logfile(\"log-\" + str(hgrid) + \".yaml\")\n",
    "log.log[\"Memory Consumption Report\"][\"Memory occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(magic_dataset.results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
